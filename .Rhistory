labs(title = title,
x = xlabel,
y = ylabel,
subtitle = subtitle)+
xlim(lims)+ylim(lims)
return(p1)
}
histogram <- function(dataset, var1, title = waiver(), xlabel = waiver(), ylabel = waiver(), subtitle = waiver(), lims = waiver()){
#' way of plotting correlations to make it consistent across plots in the paper
#' @param dataset data.frame containing all data needed in long format
#' @param var1 variable 1,
#' @param title str (optional)
#' @param xlabel str, label of x axis (optional)
#' @param ylabel str (optional)
#' @param subtitle, optional, str
#' @return ggplot object
p <- ggplot(dataset, aes(var1)) + geom_histogram(binwidth = 0.05)+
labs(title = title,
x = xlabel,
y = ylabel,
subtitle = subtitle)+
coord_cartesian(xlim = lims)
return(p)
}
mulitcol_hist <- function(dataset, var1, var2, title = waiver(), xlabel = waiver(), ylabel = waiver(), subtitle = waiver(), lims = waiver(), labeller = waiver()){
#' way of plotting correlations to make it consistent across plots in the paper
#' @param dataset data.frame containing all data needed in long format
#' @param var1 variable 1,
#' @param title str (optional)
#' @param xlabel str, label of x axis (optional)
#' @param ylabel str (optional)
#' @param subtitle, optional, str
#' @return ggplot object
anx <- "#E31A1C"
neut <- "#FFD92F"
baseline <-  "#B3B3B3"
p <- ggplot(dataset, aes(x  = var1, y = var2, fill = var1)) +
geom_col(color = "black")+
geom_errorbar(aes(ymin = var2 -se, ymax = var2 + se), width = 0.3)+
facet_wrap( vars(model),
labeller =  labeller)  +
#scale_fill_manual(name = "Induction", values = c(anx, baseline, neut))+
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none")+
labs(x = xlabel,
y = ylabel,
title = title)+
#scale_x_discrete(limits = c("anxious", "neutral", "baseline"))+
coord_cartesian(ylim = lims)
return(p)
}
models <- c("GPTdavinci-002", "GPT3", "GPT4", "GPTclaude", "bison") # weird naming, means what is written above
if(exists("allInductions")){rm(allInductions)}
for (i in models){
induced <- read.csv(paste("data/contInductions/testAllTheInductionsOn", i, ".csv", sep = ""))
neutral <- read.csv(paste("data/robustness/noPreprompt", i, ".csv", sep = ""))
neutral$version <-  qs$version
neutral <- subset(neutral, version == 0)
neutral <- pivot_longer(neutral, cols = c(3:26), names_to = "run", values_to = "outcome")
neutral <- ddply(neutral, ~run, summarise,sticsa = mean(outcome), sd = sd(outcome))
neutral$prompt <- "none"
neutral <- data.frame(X = 1:nrow(neutral),
prompt = neutral$prompt,
sticsa = neutral$sticsa,
sd = neutral$sd)
induced <- rbind(induced, neutral)
induced$model <- i
if(!exists("allInductions")){allInductions <- induced}
else {allInductions <- rbind(allInductions, induced)}
}
qs <- read.csv("inductionTexts/questionsFinal.csv", sep = ";")
qs <- qs[qs$version == 0 | qs$version == 3, ]
models <- c("GPTdavinci-002", "GPT3", "GPT4", "GPTclaude", "bison") # weird naming, means what is written above
if(exists("allInductions")){rm(allInductions)}
for (i in models){
induced <- read.csv(paste("data/contInductions/testAllTheInductionsOn", i, ".csv", sep = ""))
neutral <- read.csv(paste("data/robustness/noPreprompt", i, ".csv", sep = ""))
neutral$version <-  qs$version
neutral <- subset(neutral, version == 0)
neutral <- pivot_longer(neutral, cols = c(3:26), names_to = "run", values_to = "outcome")
neutral <- ddply(neutral, ~run, summarise,sticsa = mean(outcome), sd = sd(outcome))
neutral$prompt <- "none"
neutral <- data.frame(X = 1:nrow(neutral),
prompt = neutral$prompt,
sticsa = neutral$sticsa,
sd = neutral$sd)
induced <- rbind(induced, neutral)
induced$model <- i
if(!exists("allInductions")){allInductions <- induced}
else {allInductions <- rbind(allInductions, induced)}
}
################# Fig 0 anxiety scores ##############
qs <- read.csv("inductionTexts/questions_v2.csv", sep = ";")
qs <- qs[qs$version == 0 | qs$version == 3, ]
models <- c("GPTdavinci-002", "GPT3", "GPT4", "GPTclaude", "bison") # weird naming, means what is written above
if(exists("allInductions")){rm(allInductions)}
for (i in models){
induced <- read.csv(paste("data/contInductions/testAllTheInductionsOn", i, ".csv", sep = ""))
neutral <- read.csv(paste("data/robustness/noPreprompt", i, ".csv", sep = ""))
neutral$version <-  qs$version
neutral <- subset(neutral, version == 0)
neutral <- pivot_longer(neutral, cols = c(3:26), names_to = "run", values_to = "outcome")
neutral <- ddply(neutral, ~run, summarise,sticsa = mean(outcome), sd = sd(outcome))
neutral$prompt <- "none"
neutral <- data.frame(X = 1:nrow(neutral),
prompt = neutral$prompt,
sticsa = neutral$sticsa,
sd = neutral$sd)
induced <- rbind(induced, neutral)
induced$model <- i
if(!exists("allInductions")){allInductions <- induced}
else {allInductions <- rbind(allInductions, induced)}
}
allInductions$category[allInductions$prompt == "none"] <- "baseline"
allInductions$category[grep("fact", allInductions$prompt)] <- "neutral"
allInductions$category[grep("anxious", allInductions$prompt)] <- "anxious"
allInductions <- subset(allInductions, !grepl("happy", prompt))
View(allInductions)
allInductions <- subset(allInductions, !grepl("happy", prompt) & !grepl("a little", prompt) & ! grepl("moderately", prompt) & !grepl("very", prompt))
View(allInductions)
agg <- ddply(allInductions, ~prompt+X+category, summarise, sd = sd(sticsa), sticsa = mean(sticsa))
agg$model <- "aggregate"
df <- rbind(allInductions, agg)
agg2 <- ddply(df, ~category+model, summarise, se = se(sticsa), sticsa = mean(sticsa))
###### plotting
library(ggsignif)
fig2 <- mulitcol_hist(agg2, agg2$category, agg2$sticsa, xlabel = element_blank(), ylabel = "STICSA",
labeller = as_labeller(c("GPT3" = "GPT-3.5", "GPTclaude" = "claude-v1", "GPTdavinci-002" = "GPT-3", "aggregate" = "aggregate",
"bison" = "bison 1", "GPT4" = "GPT-4" )), lims = c(1, 5))
fig2 <- fig2 +    geom_signif(data = df, aes(category, sticsa, fill = category, group = category), comparisons = list(c("anxious", "baseline")), test = "t.test", map_signif_level = T, y_position = 4.2) +
geom_signif(data = df, aes(category, sticsa, fill = category, group = category), comparisons = list(c("anxious", "neutral")), test = "t.test", map_signif_level = T, y_position = 3.6)
fig2
anx <- "#E31A1C"
neut <- "#FFD92F"
baseline <-  "#B3B3B3"
models <- c("GPTdavinci-002", "GPT3", "GPT4", "GPTclaude", "bison") # weird naming, means what is written above
if(exists("allInductions")){rm(allInductions)}
for (i in models){
induced <- read.csv(paste("data/contInductions/testAllTheInductionsOn", i, ".csv", sep = ""))
neutral <- read.csv(paste("data/robustness/noPreprompt", i, ".csv", sep = ""))
neutral$version <-  qs$version
neutral <- subset(neutral, version == 0)
neutral <- pivot_longer(neutral, cols = c(3:26), names_to = "run", values_to = "outcome")
neutral <- ddply(neutral, ~run, summarise,sticsa = mean(outcome), sd = sd(outcome))
neutral$prompt <- "none"
neutral <- data.frame(X = 1:nrow(neutral),
prompt = neutral$prompt,
sticsa = neutral$sticsa,
sd = neutral$sd)
induced <- rbind(induced, neutral)
induced$model <- i
if(!exists("allInductions")){allInductions <- induced}
else {allInductions <- rbind(allInductions, induced)}
}
### 3 categories: no preprompt (baseline), anxious, neutral
allInductions$category[allInductions$prompt == "none"] <- "baseline"
allInductions$category[grep("fact", allInductions$prompt)] <- "neutral"
allInductions$category[grep("anxious", allInductions$prompt)] <- "anxious"
allInductions <- subset(allInductions, !grepl("happy", prompt) & !grepl("a little", prompt) & ! grepl("moderately", prompt) & !grepl("very", prompt))
agg <- ddply(allInductions, ~prompt+X+category, summarise, sd = sd(sticsa), sticsa = mean(sticsa))
agg$model <- "aggregate"
df <- rbind(allInductions, agg)
agg2 <- ddply(df, ~category+model, summarise, se = se(sticsa), sticsa = mean(sticsa))
###### plotting
library(ggsignif)
fig2 <- mulitcol_hist(agg2, agg2$category, agg2$sticsa, xlabel = element_blank(), ylabel = "STICSA",
labeller = as_labeller(c("GPT3" = "GPT-3.5", "GPTclaude" = "claude-v1", "GPTdavinci-002" = "GPT-3", "aggregate" = "aggregate",
"bison" = "bison 1", "GPT4" = "GPT-4" )), lims = c(1, 5))
fig2 <- fig2 +    geom_signif(data = df, aes(category, sticsa, fill = category, group = category), comparisons = list(c("anxious", "baseline")), test = "t.test", map_signif_level = T, y_position = 4.2) +
geom_signif(data = df, aes(category, sticsa, fill = category, group = category), comparisons = list(c("anxious", "neutral")), test = "t.test", map_signif_level = T, y_position = 3.6)
fig2
mulitcol_hist <- function(dataset, var1, var2, title = waiver(), xlabel = waiver(), ylabel = waiver(), subtitle = waiver(), lims = waiver(), labeller = waiver()){
#' way of plotting correlations to make it consistent across plots in the paper
#' @param dataset data.frame containing all data needed in long format
#' @param var1 variable 1,
#' @param title str (optional)
#' @param xlabel str, label of x axis (optional)
#' @param ylabel str (optional)
#' @param subtitle, optional, str
#' @return ggplot object
anx <- "#E31A1C"
neut <- "#FFD92F"
baseline <-  "#B3B3B3"
p <- ggplot(dataset, aes(x  = var1, y = var2, fill = var1)) +
geom_col(color = "black")+
geom_errorbar(aes(ymin = var2 -se, ymax = var2 + se), width = 0.3)+
facet_wrap( vars(model),
labeller =  labeller)  +
scale_fill_manual(name = "Induction", values = c(anx, baseline, neut))+
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none")+
labs(x = xlabel,
y = ylabel,
title = title)+
scale_x_discrete(limits = c("anxious", "neutral", "baseline"))+
coord_cartesian(ylim = lims)
return(p)
}
models <- c("GPTdavinci-002", "GPT3", "GPT4", "GPTclaude", "bison") # weird naming, means what is written above
if(exists("allInductions")){rm(allInductions)}
for (i in models){
induced <- read.csv(paste("data/contInductions/testAllTheInductionsOn", i, ".csv", sep = ""))
neutral <- read.csv(paste("data/robustness/noPreprompt", i, ".csv", sep = ""))
neutral$version <-  qs$version
neutral <- subset(neutral, version == 0)
neutral <- pivot_longer(neutral, cols = c(3:26), names_to = "run", values_to = "outcome")
neutral <- ddply(neutral, ~run, summarise,sticsa = mean(outcome), sd = sd(outcome))
neutral$prompt <- "none"
neutral <- data.frame(X = 1:nrow(neutral),
prompt = neutral$prompt,
sticsa = neutral$sticsa,
sd = neutral$sd)
induced <- rbind(induced, neutral)
induced$model <- i
if(!exists("allInductions")){allInductions <- induced}
else {allInductions <- rbind(allInductions, induced)}
}
### 3 categories: no preprompt (baseline), anxious, neutral
allInductions$category[allInductions$prompt == "none"] <- "baseline"
allInductions$category[grep("fact", allInductions$prompt)] <- "neutral"
allInductions$category[grep("anxious", allInductions$prompt)] <- "anxious"
allInductions <- subset(allInductions, !grepl("happy", prompt) & !grepl("a little", prompt) & ! grepl("moderately", prompt) & !grepl("very", prompt))
agg <- ddply(allInductions, ~prompt+X+category, summarise, sd = sd(sticsa), sticsa = mean(sticsa))
agg$model <- "aggregate"
df <- rbind(allInductions, agg)
agg2 <- ddply(df, ~category+model, summarise, se = se(sticsa), sticsa = mean(sticsa))
###### plotting
library(ggsignif)
fig2 <- mulitcol_hist(agg2, agg2$category, agg2$sticsa, xlabel = element_blank(), ylabel = "STICSA",
labeller = as_labeller(c("GPT3" = "GPT-3.5", "GPTclaude" = "claude-v1", "GPTdavinci-002" = "GPT-3", "aggregate" = "aggregate",
"bison" = "bison 1", "GPT4" = "GPT-4" )), lims = c(1, 5))
fig2 <- fig2 +    geom_signif(data = df, aes(category, sticsa, fill = category, group = category), comparisons = list(c("anxious", "baseline")), test = "t.test", map_signif_level = T, y_position = 4.2) +
geom_signif(data = df, aes(category, sticsa, fill = category, group = category), comparisons = list(c("anxious", "neutral")), test = "t.test", map_signif_level = T, y_position = 3.6)
# fig2 <- ggplot(df, aes(x = category, y = sticsa, fill = category, group = category)) +
#   geom_b
fig2
?ggsave
ggsave(filename = "plots/Fig2Induction.svg", plot = fig2, width = 9, height = 4.3, device = "svg")
install.packages("svglite")
ggsave(filename = "plots/Fig2Induction.svg", plot = fig2, width = 9, height = 4.3, device = "svg")
leftToParticipate <- read.csv("/Users/kristinwitte/Documents/GitHub/exploration-psychometrics/data/wave2/leftToParticipate.csv")
View(leftToParticipate)
leftToParticipate[leftToParticipate$x == "6543bd9e421ae38ae700049f"]
leftToParticipate[leftToParticipate$x == "59d3e110cafa460001f840f6"]
leftToParticipate[leftToParticipate$x == "60a10200728a071b878a50f9"]
leftToParticipate[leftToParticipate$x == "59d3e110cafa460001f840f6"]
leftToParticipate$X[leftToParticipate$x == "633599d83df1823b08ae2e61"]
leftToParticipate$X[leftToParticipate$x == "6085a4cc5f5f9ba1a3bfd785"]
!is.element(exclusions$X..PID..[exclusions$X..exclude... == 0], prolific$Participant.id)
library(tidyverse)
library(ggplot2)
library(jsonlite)
theme_set(theme_classic(base_size = 14))
setwd("/Users/kristinwitte/Documents/GitHub/exploration-psychometrics")
session = 2
s = session-1
load(paste("task/maxRewards", session,".Rda", sep = ""))
dir = "data/wave2/"
#load("data/wave2/bandits.Rda")
#######################################
json_to_tibble <- function(path_file) {
js_txt <- read_file(path_file)
js_txt <-str_c("[", str_replace_all(js_txt, "\\}", "\\},"), "]")
js_txt <- str_replace(js_txt, ",\n]", "]")
my_tbl <- jsonlite::fromJSON(js_txt) %>% as_tibble()
return(my_tbl)
}
files_all = list.files(path = paste(dir, "bandits/", sep = ""))
files <- files_all[!grepl("temp", files_all)]
### get IDs of participants that have questionnaire data (and thus seem to have completed the study)
qfiles = list.files(path = paste(dir, "qs/", sep = ""))
qPIDs = apply(as.array(qfiles), 1, function(x) substr(x, 1, gregexpr("_", x)[[1]][1]-1))
### get IDs of participants that completed bandits bc some of them might not have questionnaire data for some reason
bPIDs = apply(as.array(files), 1, function(x) substr(x, 1, gregexpr("_", x)[[1]][1]-1))
# merge both lists
PIDs = unique(c(qPIDs, bPIDs))
bonus <- data.frame(ID = 1:length(PIDs),
PID = PIDs,
TotalBonus = NA,
Horizon = NA,
Sam = NA,
Restless = NA,
OS = NA,
WMU = NA,
SS = NA,
attention = NA)
############# get proportion correct for all tasks #######
for (i in 1:length(PIDs)){
if (i %% 20 == 0){print(paste(i, "of", length(PIDs)))}
### bandits
temp <- try(fromJSON(paste(dir, "bandits/",PIDs[i],"_data_task_bonus_undefined_session_", s,".txt", sep = "")))
if(is.element("try-error", class(temp))){print(PIDs[i])}
else{
horizonPoints <- temp$horizon$taskReward/maxHorizon
bonus$Horizon[i] <- horizonPoints
samPoints <- temp$sam$taskReward/maxSam
bonus$Sam[i] <- samPoints
restlessPoints <- temp$restless$taskReward/maxRestless
bonus$Restless[i] <- restlessPoints
}
### OS
OS <- try(json_to_tibble(paste(dir, "OS/OS_recall_",s,"_", PIDs[i], ".json", sep = "")))
if(is.element("try-error", class(OS))){print(PIDs[i])}
else {
maxOS <- mean(OS$set_size[OS$is_practice == 0])
bonus$OS[bonus$PID == PIDs[i]] <- mean(OS$n_correct[OS$is_practice == 0])/maxOS
}
### WMU
WMU <- try(json_to_tibble(paste(dir, "WMU/WMU_",s,"_", PIDs[i], ".json", sep = "")))
if(is.element("try-error", class(WMU))){print(PIDs[i])}
else {
maxWMU <- 5 # set size is always 4 in our study
bonus$WMU[bonus$PID == PIDs[i]] <- mean(WMU$n_correct[WMU$is_practice == 0])/maxWMU
}
## SS
SS <- try(json_to_tibble(paste(dir, "SS/SS_recall_",s,"_", PIDs[i], ".json", sep = "")))
if(is.element("try-error", class(SS))){print(PIDs[i]); next}
maxSS <- mean(SS$set_size[SS$is_practice == 0])
bonus$SS[bonus$PID == PIDs[i]] <- mean(SS$n_correct[SS$is_practice == 0])/maxSS
}
######### attention ##########
files = list.files(path = paste(dir, "qs/", sep = ""))
for (i in 1:length(files)){
temp <- fromJSON(paste(dir, "qs/",files[i], sep = ""))
ID <- substr(files[i], 1, gregexpr("_", files[i])[[1]][1]-1)
bonus$attention[bonus$PID == ID] <- temp$attention1
}
###### bandits #########
#
# horizonrew <- ddply(horizon, ~ID,summarise, reward = sum(reward, na.rm = T))
#
# horizonrew$reward[horizonrew$reward == 0] <- NA# somehow NA turned into 0 so fix that
# samrew <- ddply(sam, ~ID, summarise, reward = sum(reward, na.rm = T))
# samrew$reward[samrew$reward == 0] <- NA
# restlessrew <- ddply(restless, ~ID, summarise, reward = sum(reward, na.rm = T))
# restlessrew$reward[restlessrew$reward == 0] <- NA
# bonus$Horizon[match(horizonrew$ID, bonus$ID)] <- horizonrew$reward/maxHorizon
# bonus$Sam[match(samrew$ID, bonus$ID)] <- samrew$reward/maxSam
# bonus$Restless[match(restlessrew$ID, bonus$ID)] <- restlessrew$reward/maxRestless
########## total bonus ########
bonus$TotalBonus <- round(rowMeans(bonus[ ,4:9], na.rm = T), digits = 2)
min(bonus$TotalBonus)
max(bonus$TotalBonus)
bonus$TotalBonus <-(bonus$TotalBonus - min(bonus$TotalBonus)) / (max(bonus$TotalBonus) - min(bonus$TotalBonus)) * max(bonus$TotalBonus)
# min-max normalisation but then rescaled by max value so that best person does not get max bonus but instead their proportion
bonus$TotalBonus <- bonus$TotalBonus *6
min(bonus$TotalBonus)
max(bonus$TotalBonus)
bonus$TotalBonus[bonus$attention < 1] <- 0
hist(bonus$TotalBonus, breaks = 100)
############# add bonus from wave 1 ##########
wave1 <- read.csv("data/wave1/bonus.csv")
bonus$wave1 <- wave1$TotalBonus[match(bonus$PID, wave1$PID)]
bonus$GrandTotalBonus <- bonus$TotalBonus + bonus$wave1
table(is.na(bonus$GrandTotalBonus))
hist(bonus$GrandTotalBonus)
prolific <- read.csv("data/wave2/prolific_export.csv")
externals <- bonus$PID[!is.element(bonus$PID, prolific$Participant.id)]
externals
bonus$GrandTotalBonus[bonus$PID == externals]
bonus$GrandTotalBonus[bonus$PID == externals] + 9
bonus <- subset(bonus, !is.element(PID, externals))
########## who should do the study but hasn't? ########
exclusions <- read.csv("data/wave1/exclusions.csv", stringsAsFactors = F, quote = "") # the file got messed up when saving but redoing takes forever
# remove excess quotation marks on the variables where it matters
exclusions$X..exclude... <- as.numeric(substr(exclusions$X..exclude..., start = 1, stop = 1))
exclusions$X..PID.. <- substr(exclusions$X..PID.., start = 3, stop = nchar(exclusions$X..PID..)-2)
exclusions <- subset(exclusions, X..exclude... == 0)
leftToParticipate <- exclusions$X..PID..[!is.element(exclusions$X..PID.., prolific$Participant.id)]
oldLTP <- read.csv("/Users/kristinwitte/Documents/GitHub/exploration-psychometrics/data/wave2/leftToParticipate.csv")
shouldNotHaveReceived <- !is.element(oldLTP$x, leftToParticipate)
shouldNotHaveReceived
shouldNotHaveReceived <- oldLTP$x[!is.element(oldLTP$x, leftToParticipate)]
library(tidyverse)
library(ggplot2)
library(jsonlite)
theme_set(theme_classic(base_size = 14))
setwd("/Users/kristinwitte/Documents/GitHub/exploration-psychometrics")
session = 2
s = session-1
load(paste("task/maxRewards", session,".Rda", sep = ""))
dir = "data/wave2/"
#load("data/wave2/bandits.Rda")
#######################################
json_to_tibble <- function(path_file) {
js_txt <- read_file(path_file)
js_txt <-str_c("[", str_replace_all(js_txt, "\\}", "\\},"), "]")
js_txt <- str_replace(js_txt, ",\n]", "]")
my_tbl <- jsonlite::fromJSON(js_txt) %>% as_tibble()
return(my_tbl)
}
files_all = list.files(path = paste(dir, "bandits/", sep = ""))
files <- files_all[!grepl("temp", files_all)]
### get IDs of participants that have questionnaire data (and thus seem to have completed the study)
qfiles = list.files(path = paste(dir, "qs/", sep = ""))
qPIDs = apply(as.array(qfiles), 1, function(x) substr(x, 1, gregexpr("_", x)[[1]][1]-1))
### get IDs of participants that completed bandits bc some of them might not have questionnaire data for some reason
bPIDs = apply(as.array(files), 1, function(x) substr(x, 1, gregexpr("_", x)[[1]][1]-1))
# merge both lists
PIDs = unique(c(qPIDs, bPIDs))
bonus <- data.frame(ID = 1:length(PIDs),
PID = PIDs,
TotalBonus = NA,
Horizon = NA,
Sam = NA,
Restless = NA,
OS = NA,
WMU = NA,
SS = NA,
attention = NA)
############# get proportion correct for all tasks #######
for (i in 1:length(PIDs)){
if (i %% 20 == 0){print(paste(i, "of", length(PIDs)))}
### bandits
temp <- try(fromJSON(paste(dir, "bandits/",PIDs[i],"_data_task_bonus_undefined_session_", s,".txt", sep = "")))
if(is.element("try-error", class(temp))){print(PIDs[i])}
else{
horizonPoints <- temp$horizon$taskReward/maxHorizon
bonus$Horizon[i] <- horizonPoints
samPoints <- temp$sam$taskReward/maxSam
bonus$Sam[i] <- samPoints
restlessPoints <- temp$restless$taskReward/maxRestless
bonus$Restless[i] <- restlessPoints
}
### OS
OS <- try(json_to_tibble(paste(dir, "OS/OS_recall_",s,"_", PIDs[i], ".json", sep = "")))
if(is.element("try-error", class(OS))){print(PIDs[i])}
else {
maxOS <- mean(OS$set_size[OS$is_practice == 0])
bonus$OS[bonus$PID == PIDs[i]] <- mean(OS$n_correct[OS$is_practice == 0])/maxOS
}
### WMU
WMU <- try(json_to_tibble(paste(dir, "WMU/WMU_",s,"_", PIDs[i], ".json", sep = "")))
if(is.element("try-error", class(WMU))){print(PIDs[i])}
else {
maxWMU <- 5 # set size is always 4 in our study
bonus$WMU[bonus$PID == PIDs[i]] <- mean(WMU$n_correct[WMU$is_practice == 0])/maxWMU
}
## SS
SS <- try(json_to_tibble(paste(dir, "SS/SS_recall_",s,"_", PIDs[i], ".json", sep = "")))
if(is.element("try-error", class(SS))){print(PIDs[i]); next}
maxSS <- mean(SS$set_size[SS$is_practice == 0])
bonus$SS[bonus$PID == PIDs[i]] <- mean(SS$n_correct[SS$is_practice == 0])/maxSS
}
######### attention ##########
files = list.files(path = paste(dir, "qs/", sep = ""))
for (i in 1:length(files)){
temp <- fromJSON(paste(dir, "qs/",files[i], sep = ""))
ID <- substr(files[i], 1, gregexpr("_", files[i])[[1]][1]-1)
bonus$attention[bonus$PID == ID] <- temp$attention1
}
###### bandits #########
#
# horizonrew <- ddply(horizon, ~ID,summarise, reward = sum(reward, na.rm = T))
#
# horizonrew$reward[horizonrew$reward == 0] <- NA# somehow NA turned into 0 so fix that
# samrew <- ddply(sam, ~ID, summarise, reward = sum(reward, na.rm = T))
# samrew$reward[samrew$reward == 0] <- NA
# restlessrew <- ddply(restless, ~ID, summarise, reward = sum(reward, na.rm = T))
# restlessrew$reward[restlessrew$reward == 0] <- NA
# bonus$Horizon[match(horizonrew$ID, bonus$ID)] <- horizonrew$reward/maxHorizon
# bonus$Sam[match(samrew$ID, bonus$ID)] <- samrew$reward/maxSam
# bonus$Restless[match(restlessrew$ID, bonus$ID)] <- restlessrew$reward/maxRestless
########## total bonus ########
bonus$TotalBonus <- round(rowMeans(bonus[ ,4:9], na.rm = T), digits = 2)
min(bonus$TotalBonus)
max(bonus$TotalBonus)
bonus$TotalBonus <-(bonus$TotalBonus - min(bonus$TotalBonus)) / (max(bonus$TotalBonus) - min(bonus$TotalBonus)) * max(bonus$TotalBonus)
# min-max normalisation but then rescaled by max value so that best person does not get max bonus but instead their proportion
bonus$TotalBonus <- bonus$TotalBonus *6
min(bonus$TotalBonus)
max(bonus$TotalBonus)
bonus$TotalBonus[bonus$attention < 1] <- 0
hist(bonus$TotalBonus, breaks = 100)
############# add bonus from wave 1 ##########
wave1 <- read.csv("data/wave1/bonus.csv")
bonus$wave1 <- wave1$TotalBonus[match(bonus$PID, wave1$PID)]
bonus$GrandTotalBonus <- bonus$TotalBonus + bonus$wave1
table(is.na(bonus$GrandTotalBonus))
hist(bonus$GrandTotalBonus)
################## out of the ones in here, who participated manually, without prolific ###############
# import prolific data
prolific <- read.csv("data/wave2/prolific_export.csv")
externals <- bonus$PID[!is.element(bonus$PID, prolific$Participant.id)]
externals
bonus$GrandTotalBonus[bonus$PID == externals]
bonus$GrandTotalBonus[bonus$PID == externals] + 9
bonus <- subset(bonus, !is.element(PID, externals))
########## who should do the study but hasn't? ########
exclusions <- read.csv("data/wave1/exclusions.csv", stringsAsFactors = F, quote = "") # the file got messed up when saving but redoing takes forever
# remove excess quotation marks on the variables where it matters
exclusions$X..exclude... <- as.numeric(substr(exclusions$X..exclude..., start = 1, stop = 1))
exclusions$X..PID.. <- substr(exclusions$X..PID.., start = 3, stop = nchar(exclusions$X..PID..)-2)
exclusions <- subset(exclusions, X..exclude... == 0)
leftToParticipate <- exclusions$X..PID..[!is.element(exclusions$X..PID.., prolific$Participant.id)]
leftToParticipate
mirkoMailedExtra <- read.csv("/Users/kristinwitte/Documents/GitHub/exploration-psychometrics/data/wave2/2024-03-08-leftovers-msg.csv")
gotAnEmail <- c(oldLTP$x, mirkoMailedExtra$PID)
prolific <- read.csv("data/wave2/prolific_export.csv")
shouldNotHave <- c(gotAnEmail[!is.element(gotAnEmail, exclusions$X..PID..)], gotAnEmail[is.element(gotAnEmail, prolific$Participant.id)])
gotAnEmail[!is.element(gotAnEmail, exclusions$X..PID..)]
gotAnEmail[is.element(gotAnEmail, prolific$Participant.id)]
is.element("6085a4cc5f5f9ba1a3bfd785", shouldNotHave)
is.element("6073048f6aaf87a50bfa9787", shouldNotHave)
is.element("5e81aba4b01c3588ef5e5530", shouldNotHave)
getwd()
write.csv(shouldNotHave, "data/wave2/shouldNotHaveReceived.csv")
?write.csv
write.csv(shouldNotHave, "data/wave2/shouldNotHaveReceived.csv", row.names = F)
is.element(shouldNotHave, leftToParticipate)
View(bonus)
View(qs)

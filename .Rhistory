library(tidyverse)
log_lik <- simdat %>% group_by(Horizon) %>% summarise(log_lik = sum(log_lik))
simdat %>% group_by(Horizon) %>% summarise(log_lik = sum(log_lik))
simdat %>% group_by(Horizon) %>% summarise(log_lik = sum(chosen))
simdat %>% group_by(Horizon
)
log_lik <- simdat %>% group_by(as.factor(Horizon)) %>% summarise(log_lik = sum(log_lik))
hb <- ddply(simdat, ~Horizon, log_lik = sum(log_lik))
hb <- ddply(simdat, ~Horizon,summarise, log_lik = sum(log_lik))
View(hb)
sl1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[1]]
sl1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[1]]
sl1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[1]]
session1IDs <- unique(horizon_1$ID)
log_lik_collect <- c()
log_lik_collect_5 <- c()
log_lik_collect_10 <- c()
id = 2
find(id, session1IDs)
indexOf(id, session1IDs)
which(id, session1IDs)
h5 <- log_lik(hb1_05, newdata = subset(simdat, Horizon == -0.5))
# average over all observations (keep 1 datapoint per MCMC sample)
h5 <- rowSums(h5)
get_avg_loglik <- function(obs) {
logp <- max(obs) + log(sum(exp(obs-max(obs)))) - log(length(obs))
}
logp_5 <- get_avg_loglik(h5)
# repeat for long horizon
h10 <- rowSums(log_lik(hb1_10, newdata = subset(simdat, Horizon == 0.5)))
logp_10 <- get_avg_loglik(h10)
hb <- data.frame(Horizon = c(5, 10),
log_lik = c(logp_5, logp_10))
View(hb)
which(id, session1IDs)
?which
which(session1IDs == id)
# horizon 5
model <-sl1_05[[which(session1IDs == id)]]
logp <- logLik(model, newdata = subset(horizon_2, ID == id & Horizon == -0.5))
prob <- predict(model, newdata = subset(horizon_2, ID == id & Horizon == -0.5), type = "response")
nrow(subset(horizon_2, ID == id & Horizon == -0.5))
prob
table(is.na(prob))
model
newdata <- subset(horizon_2, ID == id & Horizon == -0.5)
newdata$prob <- predict(model, newdata = subset(horizon_2, ID == id & Horizon == -0.5), type = "response")
View(newdata)
newdata <- subset(horizon_2, ID == id & Horizon == -0.5&trial == 5)
newdata$prob <- predict(model, newdata = newdata, type = "response")
# Calculate log-likelihood
log_lik <- sum(log(newdata$prob*newdata$chosen + (1-newdata$prob)*(1-newdata$chosen)))
log_lik_collect_5 <- c(log_lik_collect_5, log_lik)
log_lik_collect_5 <- c(log_lik_collect_5, log_lik)
sl1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[1]]
sl1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[1]]
session1IDs <- unique(horizon_1$ID)
log_lik_collect_5 <- c()
log_lik_collect_10 <- c()
for (id in unique(horizon_2$ID)){
# horizon 5
model <-sl1_05[[which(session1IDs == id)]]
newdata <- subset(horizon_2, ID == id & Horizon == -0.5&trial == 5)
newdata$prob <- predict(model, newdata = newdata, type = "response")
# Calculate log-likelihood
log_lik <- sum(log(newdata$prob*newdata$chosen + (1-newdata$prob)*(1-newdata$chosen)))
log_lik_collect_5 <- c(log_lik_collect_5, log_lik)
# horizon 10
model <-sl1_10[[which(session1IDs == id)]]
newdata <- subset(horizon_2, ID == id & Horizon == 0.5&trial == 5)
newdata$prob <- predict(model, newdata = newdata, type = "response")
# Calculate log-likelihood
log_lik <- sum(log(newdata$prob*newdata$chosen + (1-newdata$prob)*(1-newdata$chosen)))
log_lik_collect_10 <- c(log_lik_collect_10, log_lik)
}
sum(log_lik_collect_10)
View(sl_by_subject)
sl1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[2]]
sl1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[2]]
convergedIDs <- intersect(sl1_05$ID[sl1_05$converged], sl1_10$ID[sl1_10$converged])
horizon_2 <- subset(horizon_2, is.element(ID, convergedIDs))
hb1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = T, full = T,no_horizon = T, save = T, use_saved = T)[[1]]
hb1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = T, full = T,no_horizon = T, save = T, use_saved = T)[[1]]
horizon_2 <- subset(horizon, is.element(ID, horizon_1$ID))
simdat <- subset(horizon_2, trial == 5)
h5 <- log_lik(hb1_05, newdata = subset(simdat, Horizon == -0.5))
# average over all observations (keep 1 datapoint per MCMC sample)
h5 <- rowSums(h5)
get_avg_loglik <- function(obs) {
logp <- max(obs) + log(sum(exp(obs-max(obs)))) - log(length(obs))
}
logp_5 <- get_avg_loglik(h5)
# repeat for long horizon
h10 <- rowSums(log_lik(hb1_10, newdata = subset(simdat, Horizon == 0.5)))
logp_10 <- get_avg_loglik(h10)
hb <- data.frame(Horizon = c(5, 10),
log_lik = c(logp_5, logp_10))
View(hb)
sl1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[1]]
sl1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[1]]
session1IDs <- unique(horizon_1$ID)
log_lik_collect_5 <- c()
log_lik_collect_10 <- c()
for (id in unique(horizon_2$ID)){
# horizon 5
model <-sl1_05[[which(session1IDs == id)]]
newdata <- subset(horizon_2, ID == id & Horizon == -0.5&trial == 5)
newdata$prob <- predict(model, newdata = newdata, type = "response")
# Calculate log-likelihood
log_lik <- sum(log(newdata$prob*newdata$chosen + (1-newdata$prob)*(1-newdata$chosen)))
log_lik_collect_5 <- c(log_lik_collect_5, log_lik)
# horizon 10
model <-sl1_10[[which(session1IDs == id)]]
newdata <- subset(horizon_2, ID == id & Horizon == 0.5&trial == 5)
newdata$prob <- predict(model, newdata = newdata, type = "response")
# Calculate log-likelihood
log_lik <- sum(log(newdata$prob*newdata$chosen + (1-newdata$prob)*(1-newdata$chosen)))
log_lik_collect_10 <- c(log_lik_collect_10, log_lik)
}
## subsample to only use the participants where session 1 converged in the subject-level models for both the long and the short horizon
sl1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[2]]
sl1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[2]]
convergedIDs <- intersect(sl1_05$ID[sl1_05$converged], sl1_10$ID[sl1_10$converged])
horizon_2 <- subset(horizon_2, is.element(ID, convergedIDs))
####### hierarchical bayesian
### get model fit to session 1
hb1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = T, full = T,no_horizon = T, save = T, use_saved = T)[[1]]
hb1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = T, full = T,no_horizon = T, save = T, use_saved = T)[[1]]
### predict responses on session 2
# 2 subjects are present in the session 2 data but not session 1 so I need to kick them out
horizon_2 <- subset(horizon2, is.element(ID, horizon_1$ID))
sl1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[2]]
sl1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[2]]
convergedIDs <- intersect(sl1_05$ID[sl1_05$converged], sl1_10$ID[sl1_10$converged])
horizon_2 <- subset(horizon_2, is.element(ID, convergedIDs))
####### hierarchical bayesian
### get model fit to session 1
hb1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = T, full = T,no_horizon = T, save = T, use_saved = T)[[1]]
hb1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = T, full = T,no_horizon = T, save = T, use_saved = T)[[1]]
### predict responses on session 2
# 2 subjects are present in the session 2 data but not session 1 so I need to kick them out
horizon_2 <- subset(horizon_2, is.element(ID, horizon_1$ID))
simdat <- subset(horizon_2, trial == 5)
## get log_lik for each sample of MCMC and transform to average log lik as described by Alireza
h5 <- log_lik(hb1_05, newdata = subset(simdat, Horizon == -0.5))
# average over all observations (keep 1 datapoint per MCMC sample)
h5 <- rowSums(h5)
get_avg_loglik <- function(obs) {
logp <- max(obs) + log(sum(exp(obs-max(obs)))) - log(length(obs))
}
logp_5 <- get_avg_loglik(h5)
# repeat for long horizon
h10 <- rowSums(log_lik(hb1_10, newdata = subset(simdat, Horizon == 0.5)))
logp_10 <- get_avg_loglik(h10)
hb <- data.frame(Horizon = c(5, 10),
log_lik = c(logp_5, logp_10))
############### subject-level
# get model fit to session 1
sl1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[1]]
sl1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[1]]
session1IDs <- unique(horizon_1$ID)
log_lik_collect_5 <- c()
log_lik_collect_10 <- c()
for (id in unique(horizon_2$ID)){
# horizon 5
model <-sl1_05[[which(session1IDs == id)]]
newdata <- subset(horizon_2, ID == id & Horizon == -0.5&trial == 5)
newdata$prob <- predict(model, newdata = newdata, type = "response")
# Calculate log-likelihood
log_lik <- sum(log(newdata$prob*newdata$chosen + (1-newdata$prob)*(1-newdata$chosen)))
log_lik_collect_5 <- c(log_lik_collect_5, log_lik)
# horizon 10
model <-sl1_10[[which(session1IDs == id)]]
newdata <- subset(horizon_2, ID == id & Horizon == 0.5&trial == 5)
newdata$prob <- predict(model, newdata = newdata, type = "response")
# Calculate log-likelihood
log_lik <- sum(log(newdata$prob*newdata$chosen + (1-newdata$prob)*(1-newdata$chosen)))
log_lik_collect_10 <- c(log_lik_collect_10, log_lik)
}
length(unique(horizon_2$ID))
sl1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[2]]
sl1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[2]]
convergedIDs <- intersect(sl1_05$ID[sl1_05$converged], sl1_10$ID[sl1_10$converged])
library(here)
load_and_prep_bandit_data <- function(session){
load(here("analysis", "bandits", sprintf("banditsWave%i.Rda", session)))
if (!is.element("KLM0", colnames(sam))) {
sam <- get_KL_into_df(sam)
save(horizon, sam, restless, file = paste("analysis/bandits/banditsWave", session, ".Rda", sep = ""))
}
if (!is.element("bayMeanL", colnames(horizon))) {
horizon$bayMeanL <- NA
horizon$bayMeanR <- NA
horizon$bayVarL <- NA
horizon$bayVarR <- NA
horizon$row <- 1:nrow(horizon)
for (i in horizon$row[horizon$trial == 5]){
horizon[horizon$row == i, grep("bay", colnames(horizon))] <- bayIncrAtOnce(i, horizon)
}
horizon$V <- scale(getV(horizon$bayMeanL, horizon$bayMeanR))
horizon$RU <- scale(getRU(horizon$bayVarL, horizon$bayVarR))
save(horizon, sam, restless, file = paste("analysis/bandits/banditsWave", session, ".Rda", sep = ""))
}
if (!is.element("delta_mean", colnames(horizon))){
horizon$mean_L <- NA
horizon$mean_R <- NA
horizon$row <- 1:nrow(horizon)
horizon$mean_L[horizon$trial == 5] <- apply(as.array(horizon$row[horizon$trial == 5]), 1, function(x) meann(horizon$reward[horizon$ID == horizon$ID[x]&
horizon$block == horizon$block[x] &
horizon$chosen == 0 &
horizon$trial < 5]))
horizon$mean_R[horizon$trial == 5] <- apply(as.array(horizon$row[horizon$trial == 5]), 1, function(x) meann(horizon$reward[horizon$ID == horizon$ID[x]&
horizon$block == horizon$block[x] &
horizon$chosen == 1&
horizon$trial < 5]))
## calculate deltas
horizon$delta_mean <- scale(horizon$mean_L - horizon$mean_R)
save(horizon, sam, restless, file = paste("analysis/bandits/banditsWave", session, ".Rda", sep = ""))
}
### remove the person that has no data
horizon <- subset(horizon,!is.na(info))
sam <- subset(sam, !is.na(chosen))
print(unique(horizon$Horizon))
print(unique(horizon$info))
horizon$Horizon <- ifelse(horizon$Horizon == 5, -0.5, 0.5)
horizon$info <- horizon$info/2
}
load_and_prep_bandit_data(1)
rm(list = ls())
library(tidyverse)
library(ggplot2)
#library(jsonlite)
library(brms)
library(here)
theme_set(theme_classic(base_size = 14))
here()
source("~/Documents/GitHub/exploration-psychometrics/analysis/recovery_utils.R")
load_and_prep_bandit_data(1)
source("~/Documents/GitHub/exploration-psychometrics/analysis/recovery_utils.R")
horizon_1 <- load_and_prep_bandit_data(1)[[1]]
source("~/Documents/GitHub/exploration-psychometrics/analysis/recovery_utils.R")
horizon_1 <- load_and_prep_bandit_data(1)[[1]]
horizon_2 <- load_and_prep_bandit_data(2)[[1]]
return(list(horizon = horizon, sam = sam, restless = restless))
source("~/Documents/GitHub/exploration-psychometrics/analysis/recovery_utils.R")
horizon_1 <- load_and_prep_bandit_data(1)$horizon
horizon_2 <- load_and_prep_bandit_data(2)$horizon
################## Model selection ##########
rm(list = ls())
library(tidyverse)
library(ggplot2)
#library(jsonlite)
library(brms)
library(here)
theme_set(theme_classic(base_size = 14))
here()
rm(list = ls())
library(tidyverse)
library(ggplot2)
#library(jsonlite)
library(brms)
library(here)
theme_set(theme_classic(base_size = 14))
source("analysis/recovery_utils.R")
horizon_1 <- load_and_prep_bandit_data(1)$horizon
horizon_2 <- load_and_prep_bandit_data(2)$horizon
se<-function(x){sd(x, na.rm = T)/sqrt(length(na.omit(x)))}
meann <- function(x){mean(x, na.rm = T)}
###### Hierachical Bayesian Implementation of Standard Wilson model
res_list_5 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", full = T, it = 8000, save = T, use_saved = T, no_horizon = T)
res_list_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", full = T, it = 8000, save = T, use_saved = T, no_horizon = T)
dfs <- list(short = res_list_5[[2]], long = res_list_10[[2]])
hf_params <- dfs %>% bind_rows(.id = 'horizon')
hf_params$ID <- parse_number(rownames(hf_params))
hf_params <- subset(hf_params, select = c("predictor", "estimate", "horizon", "ID"))
####### subject-level implementation of Standard Wilson model
subj_level_5 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ],
model = "Wilson",
bayesian = F,
full = T,
save = F,
use_saved = F,
no_horizon = T)
subj_level_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ],
model = "Wilson",
bayesian = F,
full = T,
save = F,
use_saved = F,
no_horizon = T)
short <- subj_level_5[[2]]
long <- subj_level_10[[2]]
convergedIDs <- intersect(unique(short$ID[short$converged]), unique(long$ID[long$converged]))
dfs <- list(short = short, long = long)
sl_params <- dfs %>% bind_rows(.id = 'horizon')
sl_params <- sl_params %>% relocate(horizon, .after = last_col())
sl_params <- subset(sl_params, is.element(ID, convergedIDs), select = -converged)
sl_params <- pivot_longer(sl_params, cols = 1:(ncol(sl_params)-2),names_to = "predictor", values_to = "estimate")
hf_params <- subset(hf_params, is.element(ID, convergedIDs))
sl_params$subject_level <- sl_params$estimate
params <- subset(sl_params,predictor != "X.Intercept.", select = -estimate)
hf_params <- subset(hf_params, predictor !="Intercept")
params$hierarchical <- hf_params$estimate[match(paste(params$ID, params$predictor, params$horizon), paste(hf_params$ID, hf_params$predictor, hf_params$horizon))]
######### plot correlation between subject-level estimates (T1)
# Calculate correlations for each subset
params_cor <- params %>%
group_by(predictor, horizon) %>%
summarize(cor = cor(subject_level, hierarchical))
# Merge correlations back to original data
params <- left_join(params, params_cor, by = c("predictor", "horizon"))
View(params_cor)
View(params)
rm(list = ls())
library(tidyverse)
library(ggplot2)
#library(jsonlite)
library(brms)
library(here)
theme_set(theme_classic(base_size = 14))
source("analysis/recovery_utils.R")
horizon_1 <- load_and_prep_bandit_data(1)$horizon
horizon_2 <- load_and_prep_bandit_data(2)$horizon
se<-function(x){sd(x, na.rm = T)/sqrt(length(na.omit(x)))}
meann <- function(x){mean(x, na.rm = T)}
############### Horizon task ##########
###### Hierachical Bayesian Implementation of Standard Wilson model
res_list_5 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", full = T, it = 8000, save = T, use_saved = T, no_horizon = T)
res_list_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", full = T, it = 8000, save = T, use_saved = T, no_horizon = T)
dfs <- list(short = res_list_5[[2]], long = res_list_10[[2]])
hf_params <- dfs %>% bind_rows(.id = 'horizon')
hf_params$ID <- parse_number(rownames(hf_params))
hf_params <- subset(hf_params, select = c("predictor", "estimate", "horizon", "ID"))
####### subject-level implementation of Standard Wilson model
subj_level_5 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ],
model = "Wilson",
bayesian = F,
full = T,
save = F,
use_saved = F,
no_horizon = T)
subj_level_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ],
model = "Wilson",
bayesian = F,
full = T,
save = F,
use_saved = F,
no_horizon = T)
short <- subj_level_5[[2]]
long <- subj_level_10[[2]]
convergedIDs <- intersect(unique(short$ID[short$converged]), unique(long$ID[long$converged]))
dfs <- list(short = short, long = long)
sl_params <- dfs %>% bind_rows(.id = 'horizon')
sl_params <- sl_params %>% relocate(horizon, .after = last_col())
sl_params <- subset(sl_params, is.element(ID, convergedIDs), select = -converged)
sl_params <- pivot_longer(sl_params, cols = 1:(ncol(sl_params)-2),names_to = "predictor", values_to = "estimate")
hf_params <- subset(hf_params, is.element(ID, convergedIDs))
sl_params$subject_level <- sl_params$estimate
params <- subset(sl_params,predictor != "X.Intercept.", select = -estimate)
hf_params <- subset(hf_params, predictor !="Intercept")
params$hierarchical <- hf_params$estimate[match(paste(params$ID, params$predictor, params$horizon), paste(hf_params$ID, hf_params$predictor, hf_params$horizon))]
# Calculate correlations for each subset
params_cor <- params %>%
group_by(predictor, horizon) %>%
summarize(cor = cor(subject_level, hierarchical))
# Merge correlations back to original data
params <- left_join(params, params_cor, by = c("predictor", "horizon"))
lims = c(min(c(params$subject_level, params$hierarchical)), max(c(params$subject_level, params$hierarchical)))
# Plot
ggplot(params, aes(subject_level, hierarchical)) +
geom_jitter(alpha = 0.5) +
geom_abline(aes(slope = 1, intercept = 0)) +
coord_cartesian(xlim = lims, ylim = lims) +
geom_label(aes(x = Inf, y = -Inf, label = sprintf("cor = %.2f", cor)), hjust = "inward", vjust = "inward") +
facet_grid(cols = vars(predictor), rows = vars(horizon))+
theme(strip.background = element_rect(fill = "white"))
res_list_5 <- fit_model_horizon(horizon_2[horizon_2$Horizon == -0.5, ], model = "Wilson", full = T, it = 8000, save = T, use_saved = T, no_horizon = T)
res_list_10 <- fit_model_horizon(horizon_2[horizon_2$Horizon == 0.5, ], model = "Wilson", full = T, it = 8000, save = T, use_saved = T, no_horizon = T)
dfs <- list(short = res_list_5[[2]], long = res_list_10[[2]])
hf_params2 <- dfs %>% bind_rows(.id = 'horizon')
hf_params2$ID <- parse_number(rownames(hf_params2))
hf_params2 <- subset(hf_params2, select = c("predictor", "estimate", "horizon", "ID"))
hf_params <- hf_params %>% rename(session1 = estimate)
hf_params2 <- hf_params2 %>% rename(session2 = estimate)
hf_params_all <- hf_params  %>% full_join(hf_params2, by = c("predictor", "horizon", "ID"))
subj_level_5 <- fit_model_horizon(horizon_2[horizon_2$Horizon == -0.5, ],
model = "Wilson",
bayesian = F,
full = T,
save = F,
use_saved = F,
no_horizon = T)
subj_level_10 <- fit_model_horizon(horizon_2[horizon_2$Horizon == 0.5, ],
model = "Wilson",
bayesian = F,
full = T,
save = F,
use_saved = F,
no_horizon = T)
short <- subj_level_5[[2]]
long <- subj_level_10[[2]]
convergedIDs <- intersect(unique(short$ID[short$converged]), unique(long$ID[long$converged]))
dfs <- list(short = short, long = long)
sl_params2 <- dfs %>% bind_rows(.id = 'horizon')
sl_params2 <- sl_params2 %>% relocate(horizon, .after = last_col())
sl_params2 <- subset(sl_params2, is.element(ID, convergedIDs), select = -converged)
sl_params2 <- pivot_longer(sl_params2, cols = 1:(ncol(sl_params2)-2),names_to = "predictor", values_to = "session2")
sl_params <- sl_params %>% rename(session1 = estimate)
sl_params_all <- hf_params  %>% full_join(sl_params2, by = c("predictor", "horizon", "ID"))
dfs <- list(sl = sl_params_all, hb = hf_params_all)
params <- dfs %>% bind_rows(.id = 'method')
params <- subset(params, is.element(ID, convergedIDs) & !grepl("intercept", predictor, ignore.case = T))
cors <- params %>%
group_by(method, predictor, horizon) %>%
summarize(correlation = cor(session1, session2, use = "pairwise.complete.obs"))
View(cors)
hb_fixed_5 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", full = T, it = 8000, save = T, use_saved = T, no_horizon = T)[[1]]
hb_fixed_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", full = T, it = 8000, save = T, use_saved = T, no_horizon = T)[[1]]
short <- summary(hb_fixed_5)$fixed %>% rename(lower = "l-95% CI", upper = "u-95% CI")
short$predictor <- rownames(short)
long <- summary(hb_fixed_10)$fixed %>% rename(lower = "l-95% CI", upper = "u-95% CI")
long$predictor <- rownames(long)
hb <- list(short = short, long = long) %>% bind_rows(.id = "horizon")
# this is coded weirdly so I will recode it to be higher number = more value seeking and more information seeking
hb$Estimate[hb$predictor == "delta_mean"] <- -1 * hb$Estimate[hb$predictor == "delta_mean"]
hb$lower[hb$predictor == "delta_mean"] <- -1 * hb$lower[hb$predictor == "delta_mean"]
hb$upper[hb$predictor == "delta_mean"] <- -1 * hb$upper[hb$predictor == "delta_mean"]
sl_5 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson",bayesian = F, full = T, save = F, use_saved = F, no_horizon = T)[[2]]
sl_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson",bayesian = F, full = T, save = F, use_saved = F, no_horizon = T)[[2]]
convergedIDs <- intersect(sl_5$ID[sl_5$converged], sl_10$ID[sl_10$converged])
sl_by_subject <- list(short = sl_5, long = sl_10) %>% bind_rows(.id = "horizon")
sl_by_subject <- pivot_longer(sl_by_subject, cols = -c("ID", "converged", "horizon"), names_to = "predictor", values_to = "estimate")
sl_by_subject <- subset(sl_by_subject, is.element(ID, convergedIDs), -c(converged))
# this is coded weirdly so I will recode it to be higher number = more value seeking and more information seeking
sl_by_subject$estimate[sl_by_subject$predictor == "delta_mean"] <- -1 * sl_by_subject$estimate[sl_by_subject$predictor == "delta_mean"]
sl <- plyr::ddply(sl_by_subject, ~predictor+horizon, summarise, lower = mean(estimate) - 1.96*se(estimate), upper = mean(estimate) + 1.96*se(estimate), Estimate = mean(estimate))
fixed <- list(hb = subset(hb, select = c("horizon", "predictor", "Estimate", "lower", "upper")), sl = sl) %>% bind_rows(.id = "method")
fixed <- subset(fixed, !grepl("intercept", predictor, ignore.case = T))
ggplot(fixed, aes(predictor, Estimate, fill = horizon)) + geom_col(position = position_dodge(0.9)) +
geom_errorbar(aes(ymin = lower, ymax = upper), position = position_dodge(0.9), width = 0.25)+
facet_wrap(vars(method)) + scale_fill_manual(values = c("#66C2A5", "#FC8D62"))
sl1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[2]]
sl1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[2]]
convergedIDs <- intersect(sl1_05$ID[sl1_05$converged], sl1_10$ID[sl1_10$converged])
horizon_2 <- subset(horizon_2, is.element(ID, convergedIDs))
length(unique(horizon_2$ID))
horizon_2 <- subset(horizon_2, is.element(ID, horizon_1$ID))
length(unique(horizon_2$ID)) # only 128 of the subjects that did session two had their models converge in session 1 in both horizons
hb1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = T, full = T,no_horizon = T, save = T, use_saved = T)[[1]]
hb1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = T, full = T,no_horizon = T, save = T, use_saved = T)[[1]]
horizon_2 <- subset(horizon_2, is.element(ID, horizon_1$ID))
length(unique(horizon_2$ID)) # only 128 of the subjects that did session two had their models converge in session 1 in both horizons
simdat <- subset(horizon_2, trial == 5)
h5 <- log_lik(hb1_05, newdata = subset(simdat, Horizon == -0.5))
# average over all observations (keep 1 datapoint per MCMC sample)
h5 <- rowSums(h5)
get_avg_loglik <- function(obs) {
logp <- max(obs) + log(sum(exp(obs-max(obs)))) - log(length(obs))
}
logp_5 <- get_avg_loglik(h5)
# repeat for long horizon
h10 <- rowSums(log_lik(hb1_10, newdata = subset(simdat, Horizon == 0.5)))
logp_10 <- get_avg_loglik(h10)
hb <- data.frame(Horizon = c(5, 10),
log_lik = c(logp_5, logp_10))
sl1_05 <- fit_model_horizon(horizon_1[horizon_1$Horizon == -0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[1]]
sl1_10 <- fit_model_horizon(horizon_1[horizon_1$Horizon == 0.5, ], model = "Wilson", bayesian = F, full = T,no_horizon = T, save = F, use_saved = F)[[1]]
session1IDs <- unique(horizon_1$ID)
log_lik_collect_5 <- c()
log_lik_collect_10 <- c()
for (id in unique(horizon_2$ID)){
# horizon 5
model <-sl1_05[[which(session1IDs == id)]]
newdata <- subset(horizon_2, ID == id & Horizon == -0.5&trial == 5)
newdata$prob <- predict(model, newdata = newdata, type = "response")
# Calculate log-likelihood
log_lik <- sum(log(newdata$prob*newdata$chosen + (1-newdata$prob)*(1-newdata$chosen)))
log_lik_collect_5 <- c(log_lik_collect_5, log_lik)
# horizon 10
model <-sl1_10[[which(session1IDs == id)]]
newdata <- subset(horizon_2, ID == id & Horizon == 0.5&trial == 5)
newdata$prob <- predict(model, newdata = newdata, type = "response")
# Calculate log-likelihood
log_lik <- sum(log(newdata$prob*newdata$chosen + (1-newdata$prob)*(1-newdata$chosen)))
log_lik_collect_10 <- c(log_lik_collect_10, log_lik)
}
View(hb)
View(hb)
sl <- data.frame(Horizon = c(5,10),
log_lik = c(sum(log_lik_collect_5), sum(log_lik_collect_10)))
View(sl)
log_liks <- list(hb = hb, sl = sl) %>% bind_rows(.id = "method")
View(log_liks)
ucb <- fit_model_sam(data = sam_1, model = "UCB", hierarchical = T, use_saved = T)
hybrid <- fit_model_sam(data = sam_1, model = "hybrid", hierarchical = T, use_saved = T)
########## model comparison for hybrid vs ucb in predicting session 2 from session 1 #######
sam_1 <- load_and_prep_bandit_data(1)$sam
sam_2 <- load_and_prep_bandit_data(2)$sam
ucb <- fit_model_sam(data = sam_1, model = "UCB", hierarchical = T, use_saved = T)
hybrid <- fit_model_sam(data = sam_1, model = "hybrid", hierarchical = T, use_saved = T)
View(ucb)
ucb <- fit_model_sam(data = sam_1, model = "UCB", hierarchical = T, use_saved = T)[[1]]
hybrid <- fit_model_sam(data = sam_1, model = "hybrid", hierarchical = T, use_saved = T)[[1]]
sam_2 <- subset(sam_2, is.element(ID, sam_1$ID))
sam_2$predictions_ucb <- predict(ucb, newdata = sam_2)[ ,1]
sum(-1*log(sam_2$predictions_ucb))
logp_ucb <- rowSums(log_lik(ucb, newdata = sam_2))
logp_u <- get_avg_loglik(logp_ucb)
# repeat for long horizon
logp_hybrid <- rowSums(log_lik(hybrid, newdata = sam_2))
logp_h <- get_avg_loglik(logp_hybrid)
print(sprintf("log likelihood UCB: %.2f \nlog likelihood hybrid: %.2f", logp_u, logp_h))
print(sprintf("log likelihood UCB: %.2f log likelihood hybrid: %.2f", logp_u, logp_h))
